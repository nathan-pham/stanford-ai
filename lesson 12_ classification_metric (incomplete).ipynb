{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lesson 12: classification_metric (incomplete).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOSB6GPYfIujb6Mq0JCHiNH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","source":["#@title ### Installing AI course package { run: \"auto\", form-width: \"60%\", display-mode: \"form\" }\n","\n","import os\n","original_dir = os.getcwd()\n","!git clone https://github.com/amaleki2/ai_course_materials.git\n","os.chdir('ai_course_materials')\n","!pip install -U -q .\n","os.chdir(original_dir)\n","\n","try:\n","    from ai_course import Tester\n","    print(\"installation was successful!\")\n","except:\n","    print(\"something went wrong!\")"],"metadata":{"id":"FTqtpT7AMWkM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656467036732,"user_tz":420,"elapsed":10854,"user":{"displayName":"Amir Maleki Zamenjani","userId":"03832383751331733326"}},"outputId":"32feac34-afe8-43c2-854d-a4d3ff111ca4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ai_course_materials'...\n","remote: Enumerating objects: 89, done.\u001b[K\n","remote: Counting objects: 100% (89/89), done.\u001b[K\n","remote: Compressing objects: 100% (66/66), done.\u001b[K\n","remote: Total 89 (delta 33), reused 74 (delta 18), pack-reused 0\u001b[K\n","Unpacking objects: 100% (89/89), done.\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","  Building wheel for ai-course (setup.py) ... \u001b[?25l\u001b[?25hdone\n","installation was successful!\n"]}]},{"cell_type":"markdown","metadata":{"id":"JHB4u81ZaKuM"},"source":["In this assignment, we want to look more carefully at classification problems. \n","We will discuss various classification metrics. \n"," \n","Let's implement some of these metrics first.\n","\n","Below you will implement accuracy, recall, precision and F1 scores, given the values of true and predicted labels. A test is provided for you in the following cell. Remember\n","\n","$$ Acc = \\frac{TP + TN}{TP + TN + FP + FN} $$\n","$$ Recall = \\frac{TP}{TP + FN} $$\n","$$ Precision = \\frac{TP}{TP + FP} $$\n","$$ F1 = 2 \\frac{Recall \\times Precision}{Recall + Precision}$$\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"X9x-GUjLm8FC"},"source":["def compute_accuracy(y_true, y_pred):\n","    \"\"\"\n","    computing accuracy: (TP + TN) / (TP + TN + FP + FN)\n","    :param y_true: 1d numpy array of true labels.\n","    :param y_pred: 1d numpy array of predicted labels.\n","    :return: accuracy\n","    \"\"\"\n","    accuracy = np.mean(y_true == y_pred)\n","    return accuracy\n","\n","def compute_recall(y_true, y_pred):\n","    \"\"\"\n","    computing recall: (TP) / (TP + FN)\n","    :param y_true: 1d numpy array of true labels.\n","    :param y_pred: 1d numpy array of predicted labels.\n","    :return: recall\n","    \"\"\"\n","    TP = (np.logical_and(y_true==1, y_pred==1)).sum()  # true positive\n","    FN = (np.logical_and(y_true==1, y_pred==0)).sum()  # false negative\n","    recall = TP / (TP + FN)\n","    return recall\n","\n","def compute_precision(y_true, y_pred):\n","    \"\"\"\n","    computing precision: (TP) / (TP + FP)\n","    :param y_true: 1d numpy array of true labels.\n","    :param y_pred: 1d numpy array of predicted labels.\n","    :return: precision\n","    \"\"\"\n","    TP = (np.logical_and(y_true==1, y_pred==1)).sum()  # true positive\n","    FP = (np.logical_and(y_true==0, y_pred==1)).sum()  # false negative\n","    precision = TP / (TP + FP)\n","    return precision\n","\n","def compute_F1(y_true, y_pred):\n","    \"\"\"\n","    computing F1 score: 2 * recall * precision / (recall + precision)\n","    :param y_true: 1d numpy array of true labels.\n","    :param y_pred: 1d numpy array of predicted labels.\n","    :return: F1 score\n","    \"\"\"\n","    recall = compute_recall(y_true, y_pred)\n","    precision = compute_precision(y_true, y_pred)\n","    F1 = 2 * recall * precision / (recall + precision) # 1/ (1/recall + 1/precision)\n","    return F1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbIVB15yzywJ"},"source":["The implementation above was for the purpose of better practicing python, and specially numpy. In practice, we mostly use sklearn library for such calculation\n","\n","# Diabetes dataset\n","### reading and splitting dataset\n","For the rest of the module, we are going to work with the Diabetes dataset.  Import the data and split into train test sets."]},{"cell_type":"code","metadata":{"id":"Gn7PrGL5vUak","executionInfo":{"status":"ok","timestamp":1656467107191,"user_tz":420,"elapsed":241,"user":{"displayName":"Amir Maleki Zamenjani","userId":"03832383751331733326"}}},"source":["import numpy as np\n","import pandas as pd\n","diabetes_data_path = \"ai_course_materials/data/diabetes/diabetes_clean.csv\"\n","data = pd.read_csv(diabetes_data_path)\n","X = data.drop(columns=[\"Unnamed: 0\", \"Outcome\"]).to_numpy()\n","y = data[\"Outcome\"].to_numpy()"],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyhTFC50IjOE","executionInfo":{"status":"ok","timestamp":1656467113805,"user_tz":420,"elapsed":175,"user":{"displayName":"Amir Maleki Zamenjani","userId":"03832383751331733326"}},"outputId":"c2795fe2-c57a-4c17-94c8-6d124aca8650"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 7)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":[""],"metadata":{"id":"eWI-rQkAIjYG"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l5wwbG4Gw0Qi","executionInfo":{"status":"ok","timestamp":1656467138208,"user_tz":420,"elapsed":263,"user":{"displayName":"Amir Maleki Zamenjani","userId":"03832383751331733326"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size=0.1)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDgjAbM_0nZK"},"source":["### Decision Tree\n","\n","train a decision tree. use `sklearn.metrics` library to compute and report accuracy, precision, recall and f1 \n","\n"]},{"cell_type":"code","metadata":{"id":"Q_dnjq4imsqW"},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.tree import DecisionTreeClassifier\n","tree_model = DecisionTreeClassifier()\n","tree_model.fit(X_train, y_train)\n","y_pred = tree_model.predict(X_test)\n","print('Accuracy: %0.3f' %accuracy_score(y_test, y_pred))\n","print('Precision: %0.3f' %precision_score(y_test, y_pred))\n","print('Recall: %0.3f' %recall_score(y_test, y_pred))\n","print('F1: %0.3f' %f1_score(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zKYnzM_7-TUF"},"source":["## Recall-Precision curve\n","\n","Use `sklearn.metrics.precision_recall_curve` to plot precision recall curve"]},{"cell_type":"code","metadata":{"id":"ctRzYoxqnqzf"},"source":["from sklearn.metrics import precision_recall_curve\n","import matplotlib.pyplot as plt\n","\n","precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n","\n","plt.figure(figsize=(6,6))\n","plt.plot(recall, precision, 'k', linewidth=3)\n","plt.ylabel('Precision')\n","plt.xlabel('Recall')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.0])\n","plt.gca().set_aspect('equal');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HykU3lJQ-eMv"},"source":["### ROC Curve\n","\n","use `roc_curve` from the `sklearn.metrics` library to compute false positive and true positive rate. Plot ROC curve. Use `auc` to compute the area under the curve. "]},{"cell_type":"code","metadata":{"id":"onSDTQZgnwe9"},"source":["from sklearn.metrics import roc_curve, auc\n","\n","FPR, TPR, thereshold = roc_curve(y_test, y_pred)\n","auc_value = auc(FPR, TPR)\n","plt.figure(figsize=(6,6))\n","plt.plot(FPR, TPR, \"k\", linewidth=3)\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.xlim([0, 1])\n","plt.ylim([0, 1])\n","plt.gca().set_aspect('equal')\n","print(\"auc value =%0.3f\" %auc_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lb3biWlK_hv7"},"source":["### Confusion matrix\n","Another tool for evaluating classification is confusion matrix. \n","\n","Confusion matrix shows where the predictions lie in the true-false spectrum"]},{"cell_type":"code","metadata":{"id":"TVzLphWIn7em"},"source":["from sklearn.metrics import confusion_matrix\n","confusion = confusion_matrix(y_test, y_pred)\n","confusion"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O-S8cael_kgC"},"source":["### evaluation set\n","\n","So far, we have used the default values for the input of the decision tree. \n","Perhaps the most import property of a tree is the depth, which by default does not have a maximum value (i.e. no limit).  \n","\n","Now, we are going to use  `GridSearch` to fine tune  the `max_depth` property. If we find tune the hyper parameters on the test data, that is considered as data leakage. Remember, during training, the model should NOT see the test set in any shape or form. \n","\n","One way to mediate this problem is to create another split on the train set. We will set aside a portion of train set, and call it evaluation set. We train the model on the rest of train set, and then use evaluation set for turning hyper paramters. When training is over, and hyper parameters are tuned, then we test the model on the test set. \n"]},{"cell_type":"code","metadata":{"id":"0rnOnMfUlVFn"},"source":["# further split into train and evaluation set\n","X_train, X_eval, y_train,  y_eval = train_test_split(X_train, y_train, test_size=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh7v0bXYoLJO"},"source":["from sklearn.model_selection import GridSearchCV\n","# tune the max_depth using grid search and optimize for recall."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tlQ8u805o9vu"},"source":["Last week we learn about Logistic Regression model as our very first linear classification model. Other linear classifiction models implemented in sklearn include `SGDClassifier`, `PassiveAggressiveClassifier` and `RidgeClassifier`. They all share a parameter `C` which is the inverse of regularization coefficient. (i.e. large `C` means weaker regularization). \n","\n","Use GridSearch to find the optimal value of the regularization parameters for each of these models. Use Recall as the metric. Remember for `SGDClassifer` and `RidgeClassifier`, the regularization parameters is $\\alpha$. For `LogisticRegression` and `PassiveAgressiveClassifier`, we have parameter `C` which corresponds to $2/\\alpha$. "]},{"cell_type":"code","metadata":{"id":"lNTJyfKkmrPE"},"source":["from sklearn.linear_model import LogisticRegression\n","# train a logistic regression. Make sure to tune the the important hyper parameters and optimize for recall"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6p6AHoxRqY4b"},"source":["from sklearn.linear_model import RidgeClassifier\n","# train a linear model with Ridge regularizer. Make sure to tune the the important hyper parameters and optimize for recall"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SByl9TZDs0iu"},"source":["Now use a random forest model. "]},{"cell_type":"code","metadata":{"id":"16kWxbFUsv-z"},"source":["# choose other models, train them and use grid search to tune the hyperparameters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwadZpsxtmcT"},"source":["# Example with multi-class classification\n","\n","Most metrics we studied are for binary classification (labels =0 and 1). For the case of multi-label classification, confusion matrix is a useful tool. \n","\n","To practice this here we import digit dataset which contains images of digits 0-9. \n","All images are 8 by 8 pixels, which are flattens to 1d numpy arrays with 64 entries. \n","\n","Let's plot some of these"]},{"cell_type":"code","metadata":{"id":"S2phIH7Rt6II"},"source":["from sklearn.datasets import load_digits\n","dataset = load_digits()\n","X, y = dataset.data, dataset.target\n","\n","\n","plt.figure(figsize=(8,8))\n","for i in range(12):\n","    plt.subplot(4, 3, i+1) \n","    plt.imshow(X[20*i, :].reshape(8, 8)) \n","    plt.xticks([], [])\n","    plt.yticks([], [])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCjAT5XOpUQB"},"source":["# choose other models, train them and use grid search to tune the hyperparameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-XZsET2F3Sk"},"source":["X_test_missed = X_test[y_test != y_pred, :]\n","y_test_missed = y_test[y_test != y_pred]\n","y_pred_missed = y_pred[y_test != y_pred]\n","\n","n_error = X_test_missed.shape[0]\n","\n","plt.figure(figsize=(8,8))\n","for i in range(n_error):\n","    plt.subplot(n_error // 3 + 1, 3, i+1)\n","    plt.imshow(X_test_missed[i, :].reshape(8, 8))\n","    plt.xticks([], [])\n","    plt.yticks([], [])\n","    plt.title(\"%d, predicted %d\" %(y_test_missed[i], y_pred_missed[i]))"],"execution_count":null,"outputs":[]}]}